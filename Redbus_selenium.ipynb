{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6fb42cbc-3094-451b-8961-8208f30967eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Bangalore to Kozhikode\n",
      "Successfully completed data extraction for route: Kozhikode to Ernakulam\n",
      "Successfully completed data extraction for route: Kozhikode to Bangalore\n",
      "Successfully completed data extraction for route: Ernakulam to Kozhikode\n",
      "Successfully completed data extraction for route: Kozhikode to Thrissur\n",
      "Successfully completed data extraction for route: Kozhikode to Thiruvananthapuram\n",
      "Successfully completed data extraction for route: Thrissur to Kozhikode\n",
      "Successfully completed data extraction for route: Bangalore to Kalpetta (kerala)\n",
      "Successfully completed data extraction for route: Kalpetta (kerala) to Bangalore\n",
      "Successfully completed data extraction for route: Kottayam to Kozhikode\n",
      "Successfully completed data extraction for route: Thiruvananthapuram to Kozhikode\n",
      "Successfully completed data extraction for route: Kannur (Kerala) to Bangalore\n",
      "Successfully completed data extraction for route: Kozhikode to Aluva\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/ksrtc-kerala/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  \n",
    "\n",
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False  \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break  \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"ksrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)        \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")        \n",
    "        \n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"ksrtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "aad83b69-410e-40be-becb-c845bdda66a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path=r\"D:/files/project/ksrtc1.csv\"\n",
    "\n",
    "# df_buses.to_csv(path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9f37bdc0-5abd-4525-88e4-f1e57b73f50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "Navigating to page 4\n",
      "Navigating to page 5\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Kakinada to Visakhapatnam\n",
      "Successfully completed data extraction for route: Chittoor (Andhra Pradesh) to Bangalore\n",
      "Successfully completed data extraction for route: Tirupati to Bangalore\n",
      "Successfully completed data extraction for route: Hyderabad to Ongole\n",
      "Successfully completed data extraction for route: Ongole to Hyderabad\n",
      "Successfully completed data extraction for route: Visakhapatnam to Kakinada\n",
      "Successfully completed data extraction for route: Kadiri to Bangalore\n",
      "Successfully completed data extraction for route: Vinukonda to Hyderabad\n",
      "Successfully completed data extraction for route: Bangalore to Kadiri\n",
      "Successfully completed data extraction for route: Hyderabad to Narasaraopet\n",
      "Successfully completed data extraction for route: Madanapalli to Bangalore\n",
      "Successfully completed data extraction for route: Narasaraopet to Hyderabad\n",
      "Successfully completed data extraction for route: Rajahmundry to Visakhapatnam\n",
      "Successfully completed data extraction for route: Eluru to Hyderabad\n",
      "Successfully completed data extraction for route: Chennai to Tirupati\n",
      "Successfully completed data extraction for route: Bangalore to Madanapalli\n",
      "Successfully completed data extraction for route: Rayachoti to Bangalore\n",
      "Successfully completed data extraction for route: Tirupati to Chennai\n",
      "Successfully completed data extraction for route: Visakhapatnam to Vijayawada\n",
      "Successfully completed data extraction for route: Rajahmundry to Vijayawada\n",
      "Successfully completed data extraction for route: Hyderabad to Guntur (Andhra Pradesh)\n",
      "Successfully completed data extraction for route: Macherla (andhra pradesh) to Hyderabad\n",
      "Successfully completed data extraction for route: Nandyal to Hyderabad\n",
      "Successfully completed data extraction for route: Hyderabad to Eluru\n",
      "Successfully completed data extraction for route: Bangalore to Rayachoti\n",
      "Successfully completed data extraction for route: Kurnool to Hyderabad\n",
      "Successfully completed data extraction for route: Hyderabad to Vinukonda\n",
      "Successfully completed data extraction for route: Vijayawada to Visakhapatnam\n",
      "Successfully completed data extraction for route: Kurnool to Bangalore\n",
      "Successfully completed data extraction for route: Rajahmundry to Hyderabad\n",
      "Successfully completed data extraction for route: Amalapuram to Visakhapatnam\n",
      "Successfully completed data extraction for route: Kurnool to Vijayawada\n",
      "Successfully completed data extraction for route: Visakhapatnam to Rajahmundry\n",
      "Successfully completed data extraction for route: Hyderabad to Macherla (andhra pradesh)\n",
      "Successfully completed data extraction for route: Nellore to Bangalore\n",
      "Successfully completed data extraction for route: Tadipatri to Bangalore\n",
      "Successfully completed data extraction for route: Kakinada to Vijayawada\n",
      "Successfully completed data extraction for route: Visakhapatnam to Amalapuram\n",
      "Successfully completed data extraction for route: Hyderabad to Markapuram\n",
      "Successfully completed data extraction for route: Hyderabad to Nandyal\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "URL =\"https://www.redbus.in/online-booking/apsrtc/?utm_source=rtchometile \"\n",
    "\n",
    "# Initialize WebDriver\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "# Load the page\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)\n",
    "        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False  \n",
    "\n",
    "# Main scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break  \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"APsrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # Now scrape detailed information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "\n",
    "        # Open the route link\n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # Handle the 'book now' button click if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating\n",
    "        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "        \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "        \n",
    "        \n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"APsrtc_bus_details1.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "23c5d7c8-648d-4ea5-9d92-89fd428d6ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Khammam to Hyderabad\n",
      "Successfully completed data extraction for route: Hyderabad to Khammam\n",
      "Successfully completed data extraction for route: Karimnagar to Hyderabad\n",
      "Successfully completed data extraction for route: Hyderabad to Adilabad\n",
      "Successfully completed data extraction for route: Kothagudem to Hyderabad\n",
      "Successfully completed data extraction for route: Hyderabad to Mancherial\n",
      "Successfully completed data extraction for route: Guntur (Andhra Pradesh) to Hyderabad\n",
      "Successfully completed data extraction for route: Godavarikhani to Hyderabad\n",
      "Successfully completed data extraction for route: Kodad to Hyderabad\n",
      "Successfully completed data extraction for route: Hyderabad to Ongole\n",
      "Successfully completed data extraction for route: Jagityal to Hyderabad\n",
      "Successfully completed data extraction for route: Hyderabad to Nirmal\n",
      "Successfully completed data extraction for route: Hyderabad to Guntur (Andhra Pradesh)\n",
      "Successfully completed data extraction for route: Hyderabad to Karimnagar\n",
      "Successfully completed data extraction for route: Hyderabad to Kothagudem\n",
      "Successfully completed data extraction for route: Hyderabad to Bhadrachalam\n",
      "Successfully completed data extraction for route: Hyderabad to Sathupally\n",
      "Successfully completed data extraction for route: Hyderabad to Warangal\n",
      "Successfully completed data extraction for route: Hyderabad to Tirupati\n",
      "Successfully completed data extraction for route: Hyderabad to Armoor\n",
      "Successfully completed data extraction for route: Hyderabad to Godavarikhani\n",
      "Successfully completed data extraction for route: Peddapalli (Telangana) to Hyderabad\n",
      "Successfully completed data extraction for route: Hyderabad to Kodad\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/tsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  \n",
    "\n",
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False  \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break  \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"Tsrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)        \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")        \n",
    "        \n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"Tsrtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8ff20b53-6cd8-4366-9a6e-2d5808f0c389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Jodhpur to Ajmer\n",
      "Successfully completed data extraction for route: Beawar (Rajasthan) to Jaipur (Rajasthan)\n",
      "Successfully completed data extraction for route: Udaipur to Jodhpur\n",
      "Successfully completed data extraction for route: Jaipur (Rajasthan) to Jodhpur\n",
      "Successfully completed data extraction for route: Sikar to Jaipur (Rajasthan)\n",
      "Successfully completed data extraction for route: Aligarh (uttar pradesh) to Jaipur (Rajasthan)\n",
      "Successfully completed data extraction for route: Kota(Rajasthan) to Jaipur (Rajasthan)\n",
      "Successfully completed data extraction for route: Jaipur (Rajasthan) to Aligarh (uttar pradesh)\n",
      "Successfully completed data extraction for route: Kishangarh to Jaipur (Rajasthan)\n",
      "Successfully completed data extraction for route: Sikar to Bikaner\n",
      "Successfully completed data extraction for route: Jodhpur to Beawar (Rajasthan)\n",
      "Successfully completed data extraction for route: Udaipur to Pali (Rajasthan)\n",
      "Successfully completed data extraction for route: Kota(Rajasthan) to Udaipur\n",
      "Successfully completed data extraction for route: Jaipur (Rajasthan) to Bharatpur\n",
      "Successfully completed data extraction for route: Jaipur (Rajasthan) to Mathura\n",
      "Successfully completed data extraction for route: Bikaner to Sikar\n",
      "Successfully completed data extraction for route: Pali (Rajasthan) to Udaipur\n",
      "Successfully completed data extraction for route: Udaipur to Jaipur (Rajasthan)\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/rsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  \n",
    "\n",
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False  \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break  \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"Rsrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)        \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")        \n",
    "        \n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"Rsrtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "81d49d48-0278-46d4-9d3b-1938b5b3e837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "Navigating to page 4\n",
      "Navigating to page 5\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Durgapur (West Bengal) to Kolkata\n",
      "Successfully completed data extraction for route: Kolkata to Burdwan\n",
      "Successfully completed data extraction for route: Kolkata to Durgapur (West Bengal)\n",
      "Successfully completed data extraction for route: Haldia to Kolkata\n",
      "Successfully completed data extraction for route: Kolkata to Haldia\n",
      "Successfully completed data extraction for route: Midnapore to Kolkata\n",
      "Successfully completed data extraction for route: Kolkata to Arambagh (West Bengal)\n",
      "Successfully completed data extraction for route: Kolkata to Digha\n",
      "Successfully completed data extraction for route: Digha to Kolkata\n",
      "Successfully completed data extraction for route: Kolkata to Bankura\n",
      "Successfully completed data extraction for route: Kolkata to Asansol (West Bengal)\n",
      "Successfully completed data extraction for route: Kolkata to Midnapore\n",
      "Successfully completed data extraction for route: Jhargram to Kolkata\n",
      "Successfully completed data extraction for route: Kolkata to Contai (Kanthi)\n",
      "Successfully completed data extraction for route: Kolkata to Nandakumar (west bengal)\n",
      "Successfully completed data extraction for route: Durgapur (West Bengal) to Barasat (West Bengal)\n",
      "Successfully completed data extraction for route: Midnapore to Barasat (West Bengal)\n",
      "Successfully completed data extraction for route: Berhampore (West Bengal) to Durgapur (West Bengal)\n",
      "Successfully completed data extraction for route: Kolkata to Suri\n",
      "Successfully completed data extraction for route: Durgapur (West Bengal) to Digha\n",
      "Successfully completed data extraction for route: Durgapur (West Bengal) to Berhampore (West Bengal)\n",
      "Successfully completed data extraction for route: Digha to Barasat (West Bengal)\n",
      "Successfully completed data extraction for route: Kolkata to Heria\n",
      "Successfully completed data extraction for route: Kolkata to Bajkul (West Bengal)\n",
      "Successfully completed data extraction for route: Barasat (West Bengal) to Midnapore\n",
      "Successfully completed data extraction for route: Kolkata to Ramnagar (West Bengal)\n",
      "Successfully completed data extraction for route: Kolkata to Jhargram\n",
      "Successfully completed data extraction for route: Durgapur (West Bengal) to Bankura\n",
      "Successfully completed data extraction for route: Siliguri to Kolkata\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/south-bengal-state-transport-corporation-sbstc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  \n",
    "\n",
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False  \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break  \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"SBsrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)        \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")        \n",
    "        \n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"SBsrtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a00c1a80-96bc-4335-8c1d-28feeab557fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "Navigating to page 4\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Delhi to Shimla\n",
      "Successfully completed data extraction for route: Hamirpur (Himachal Pradesh) to Chandigarh\n",
      "Successfully completed data extraction for route: Chandigarh to Hamirpur (Himachal Pradesh)\n",
      "Successfully completed data extraction for route: Shimla to Delhi\n",
      "Successfully completed data extraction for route: Hamirpur (Himachal Pradesh) to Delhi\n",
      "Successfully completed data extraction for route: Delhi to Hamirpur (Himachal Pradesh)\n",
      "Successfully completed data extraction for route: Kangra to Chandigarh\n",
      "Successfully completed data extraction for route: Delhi to Chandigarh\n",
      "Successfully completed data extraction for route: Palampur to Chandigarh\n",
      "Successfully completed data extraction for route: Dharamshala (Himachal Pradesh) to Chandigarh\n",
      "Successfully completed data extraction for route: Chandigarh to Dharamshala (Himachal Pradesh)\n",
      "Successfully completed data extraction for route: Chandigarh to Palampur\n",
      "Successfully completed data extraction for route: Delhi to Nalagarh\n",
      "Successfully completed data extraction for route: Shimla to Chandigarh\n",
      "Successfully completed data extraction for route: Chandigarh to Kangra\n",
      "Successfully completed data extraction for route: Ghumarwin to Chandigarh\n",
      "Successfully completed data extraction for route: Chandigarh to Kullu\n",
      "Successfully completed data extraction for route: Manali to Chandigarh\n",
      "Successfully completed data extraction for route: Delhi to Solan\n",
      "Successfully completed data extraction for route: Shimla to Manali\n",
      "Successfully completed data extraction for route: Chandigarh to Manali\n",
      "Successfully completed data extraction for route: Solan to Delhi\n",
      "Successfully completed data extraction for route: Sunder Nagar (Himachal Pradesh) to Chandigarh\n",
      "Successfully completed data extraction for route: Delhi to Bilaspur (Himachal Pradesh)\n",
      "Successfully completed data extraction for route: Kangra to Delhi\n",
      "Successfully completed data extraction for route: Palampur to Delhi\n",
      "Successfully completed data extraction for route: Delhi to Palampur\n",
      "Successfully completed data extraction for route: Ghumarwin to Delhi\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/hrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  \n",
    "\n",
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False  \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break  \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"Hrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)        \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")        \n",
    "        \n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"Hrtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4bd0b198-0248-40ca-ad90-9ac66fd83cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "Navigating to page 4\n",
      "Navigating to page 5\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Delhi to Bareilly (Uttar Pradesh)\n",
      "Successfully completed data extraction for route: Delhi to Lucknow\n",
      "Successfully completed data extraction for route: Bareilly (Uttar Pradesh) to Delhi\n",
      "Successfully completed data extraction for route: Lucknow to Gorakhpur (uttar pradesh)\n",
      "Successfully completed data extraction for route: Delhi to Aligarh (uttar pradesh)\n",
      "Successfully completed data extraction for route: Lucknow to Delhi\n",
      "Successfully completed data extraction for route: Delhi to Farrukhabad (Uttar Pradesh)\n",
      "Successfully completed data extraction for route: Delhi to Sitapur (Uttar Pradesh)\n",
      "Successfully completed data extraction for route: Delhi to Gorakhpur (uttar pradesh)\n",
      "Successfully completed data extraction for route: Farrukhabad (Uttar Pradesh) to Delhi\n",
      "Successfully completed data extraction for route: Lucknow to Varanasi\n",
      "Successfully completed data extraction for route: Delhi to Moradabad\n",
      "Successfully completed data extraction for route: Lucknow to Ballia (Uttar Pradesh)\n",
      "Successfully completed data extraction for route: Aligarh (uttar pradesh) to Lucknow\n",
      "Successfully completed data extraction for route: Moradabad to Delhi\n",
      "Successfully completed data extraction for route: Sitapur (Uttar Pradesh) to Delhi\n",
      "Successfully completed data extraction for route: Delhi to Shahjahanpur (Uttar Pradesh)\n",
      "Successfully completed data extraction for route: Greater noida (uttar pradesh) to Lucknow\n",
      "Successfully completed data extraction for route: Kanpur (Uttar Pradesh) to Varanasi\n",
      "Successfully completed data extraction for route: Gorakhpur (uttar pradesh) to Lucknow\n",
      "Successfully completed data extraction for route: Delhi to Agra\n",
      "Successfully completed data extraction for route: Delhi to Kanpur (Uttar Pradesh)\n",
      "Successfully completed data extraction for route: Delhi to Pilibhit\n",
      "Successfully completed data extraction for route: Lucknow to Mathura\n",
      "Successfully completed data extraction for route: Kanpur (Uttar Pradesh) to Bareilly (Uttar Pradesh)\n",
      "Successfully completed data extraction for route: Dehradun to Bareilly (Uttar Pradesh)\n",
      "Successfully completed data extraction for route: Ballia (Uttar Pradesh) to Lucknow\n",
      "Successfully completed data extraction for route: Lucknow to Agra\n",
      "Successfully completed data extraction for route: Agra to Delhi\n",
      "Successfully completed data extraction for route: Gorakhpur (uttar pradesh) to Delhi\n",
      "Successfully completed data extraction for route: Jhansi(Uttar Pradesh) to Kanpur (Uttar Pradesh)\n",
      "Successfully completed data extraction for route: Mathura to Lucknow\n",
      "Successfully completed data extraction for route: Varanasi to Lucknow\n",
      "Successfully completed data extraction for route: Bareilly (Uttar Pradesh) to Agra\n",
      "Successfully completed data extraction for route: Delhi to Haldwani\n",
      "Successfully completed data extraction for route: Shahjahanpur (Uttar Pradesh) to Delhi\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/uttar-pradesh-state-road-transport-corporation-upsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  \n",
    "\n",
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False  \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break  \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"UPsrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)        \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")        \n",
    "        \n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"UPsrtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "54f4fb9b-349a-4a12-a700-29243dbf31d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "Navigating to page 4\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Patna (Bihar) to Motihari\n",
      "Successfully completed data extraction for route: Bettiah to Patna (Bihar)\n",
      "Successfully completed data extraction for route: Delhi to Motihari\n",
      "Successfully completed data extraction for route: Motihari to Agra\n",
      "Successfully completed data extraction for route: Agra to Motihari\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/bihar-state-road-transport-corporation-bsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  \n",
    "\n",
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False  \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break  \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"Bsrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)        \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")        \n",
    "        \n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"Bsrtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "eb373225-5ebc-4558-a3e1-248110651dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "Navigating to page 4\n",
      "Navigating to page 5\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Tezpur to Guwahati\n",
      "Successfully completed data extraction for route: Guwahati to Tezpur\n",
      "Successfully completed data extraction for route: Nagaon (Assam) to Guwahati\n",
      "Successfully completed data extraction for route: Guwahati to Nagaon (Assam)\n",
      "Successfully completed data extraction for route: Jorhat to Tinsukia\n",
      "Successfully completed data extraction for route: Tinsukia to Jorhat\n",
      "Successfully completed data extraction for route: Guwahati to Kaliabor\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/astc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  \n",
    "\n",
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False  \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break  \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"Astc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)        \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")        \n",
    "        \n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"Astc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "00596ff5-de0f-431d-a9f1-e32969fa9bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "Navigating to page 4\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Digha to Barasat (West Bengal)\n",
      "Successfully completed data extraction for route: Durgapur (West Bengal) to Kolkata\n",
      "Successfully completed data extraction for route: Digha to Kolkata\n",
      "Successfully completed data extraction for route: Barasat (West Bengal) to Digha\n",
      "Successfully completed data extraction for route: Kolkata to Durgapur (West Bengal)\n",
      "Successfully completed data extraction for route: Kolkata to Digha\n",
      "Successfully completed data extraction for route: Barasat (West Bengal) to Contai (Kanthi)\n",
      "Successfully completed data extraction for route: Barasat (West Bengal) to Nandakumar (west bengal)\n",
      "Successfully completed data extraction for route: Barasat (West Bengal) to Kolaghat\n",
      "Successfully completed data extraction for route: Kolkata to Suri\n",
      "Successfully completed data extraction for route: Midnapore to Kolkata\n",
      "Successfully completed data extraction for route: Midnapore to Barasat (West Bengal)\n",
      "Successfully completed data extraction for route: Barasat (West Bengal) to Heria\n",
      "Successfully completed data extraction for route: Kolkata to Asansol (West Bengal)\n",
      "Successfully completed data extraction for route: Digha to Habra\n",
      "Successfully completed data extraction for route: Haldia to Kolkata\n",
      "Successfully completed data extraction for route: Kolkata to Burdwan\n",
      "Successfully completed data extraction for route: Durgapur (West Bengal) to Purulia\n",
      "Successfully completed data extraction for route: Barasat (West Bengal) to Debra\n",
      "Successfully completed data extraction for route: Durgapur (West Bengal) to Barasat (West Bengal)\n",
      "Successfully completed data extraction for route: Kolkata to Purulia\n",
      "Successfully completed data extraction for route: Kolkata to Haldia\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/wbtc-ctc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  \n",
    "\n",
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False  \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break  \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"WBtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)        \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")        \n",
    "        \n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"WBtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5cb1bd8e-b2d2-4380-aee1-b9048a1e5d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Patiala to Delhi\n",
      "Successfully completed data extraction for route: Ludhiana to Delhi\n",
      "Successfully completed data extraction for route: Delhi to Ludhiana\n",
      "Successfully completed data extraction for route: Ludhiana to Delhi Airport\n",
      "Successfully completed data extraction for route: Delhi Airport to Patiala\n",
      "Successfully completed data extraction for route: Chandigarh to Patiala\n",
      "Successfully completed data extraction for route: Jalandhar to Delhi\n",
      "Successfully completed data extraction for route: Delhi Airport to Ludhiana\n",
      "Successfully completed data extraction for route: Jalandhar to Delhi Airport\n",
      "Successfully completed data extraction for route: Phagwara to Delhi\n",
      "Successfully completed data extraction for route: Delhi Airport to Jalandhar\n",
      "Successfully completed data extraction for route: Delhi to Amritsar\n",
      "Successfully completed data extraction for route: Phagwara to Delhi Airport\n",
      "Successfully completed data extraction for route: Delhi to Phagwara\n",
      "Successfully completed data extraction for route: Amritsar to Delhi\n",
      "Successfully completed data extraction for route: Delhi Airport to Phagwara\n",
      "Successfully completed data extraction for route: Amritsar to Delhi Airport\n",
      "Successfully completed data extraction for route: Amritsar to Patiala\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://redbus.in/online-booking/pepsu/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  \n",
    "\n",
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False  \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break  \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"Psrtc_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)        \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")        \n",
    "        \n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"Psrtc_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0be3d327-80b1-4ff9-8f50-8d11884a35e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to page 2\n",
      "Navigating to page 3\n",
      "No more pages to paginate or pagination element not found.\n",
      "Data saved to bus_routes.csv\n",
      "Successfully completed data extraction for route: Delhi to Chandigarh\n",
      "Successfully completed data extraction for route: Chandigarh to Delhi\n",
      "Successfully completed data extraction for route: Yamuna Nagar to Chandigarh\n",
      "Successfully completed data extraction for route: Ludhiana to Chandigarh\n",
      "Successfully completed data extraction for route: Chandigarh to Yamuna Nagar\n",
      "Successfully completed data extraction for route: Chandigarh to Baijnath\n",
      "Successfully completed data extraction for route: Hamirpur (Himachal Pradesh) to Chandigarh\n",
      "Successfully completed data extraction for route: Chandigarh to Ludhiana\n",
      "Successfully completed data extraction for route: Chandigarh to Dehradun\n",
      "Successfully completed data extraction for route: Chandigarh to Pathankot\n",
      "Successfully completed data extraction for route: Dehradun to Chandigarh\n",
      "Successfully completed data extraction for route: Chandigarh to Dharamshala (Himachal Pradesh)\n",
      "Successfully completed data extraction for route: Sujanpur (himachal pradesh) to Chandigarh\n",
      "Successfully completed data extraction for route: Chandigarh to Shimla\n",
      "Successfully completed data extraction for route: Dharamshala (Himachal Pradesh) to Chandigarh\n",
      "Successfully completed data extraction for route: Pathankot to Chandigarh\n",
      "Successfully completed data extraction for route: Baijnath to Chandigarh\n",
      "Successfully completed data extraction for route: Shimla to Chandigarh\n",
      "Bus details saved to bus_details.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/chandigarh-transport-undertaking-ctu\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  \n",
    "\n",
    "# Scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    try:\n",
    "        route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "        bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "        bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "        return bus_routes_link, bus_routes_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping bus routes: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Handle pagination\n",
    "def handle_pagination(driver, wait):\n",
    "    try:\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")\n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)\n",
    "        \n",
    "        next_page_button_xpath = f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\"\n",
    "        next_page_button = wait.until(EC.presence_of_element_located((By.XPATH, next_page_button_xpath)))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementNotInteractableException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)        \n",
    "        print(f\"Navigating to page {next_page_number}\")\n",
    "        time.sleep(10) \n",
    "        return True  \n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"No more pages to paginate or pagination element not found.\")\n",
    "        return False  \n",
    "\n",
    "# scraping function\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    load_page(driver, URL)\n",
    "\n",
    "    all_routes_name = []\n",
    "    all_routes_link = []\n",
    "\n",
    "    while True:\n",
    "        # Scrape routes on the current page\n",
    "        bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "        all_routes_name.extend(bus_routes_name)\n",
    "        all_routes_link.extend(bus_routes_link)\n",
    "        \n",
    "        # Handle pagination\n",
    "        if not handle_pagination(driver, wait):\n",
    "            break  \n",
    "\n",
    "    # Save route data to CSV\n",
    "    df_routes = pd.DataFrame({\"Route_name\": all_routes_name, \"Route_link\": all_routes_link})\n",
    "    df_routes.to_csv(\"CTU_bus_routes.csv\", index=False)\n",
    "    print(\"Data saved to bus_routes.csv\")\n",
    "    \n",
    "    # scrape information for each route\n",
    "    bus_details = []\n",
    "\n",
    "    for i, row in df_routes.iterrows():\n",
    "        link = row[\"Route_link\"]\n",
    "        routes = row[\"Route_name\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Click on all the route elements\n",
    "        elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "        for element in elements:\n",
    "            element.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click 'view buses' button if available\n",
    "        try:\n",
    "            clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "            clicks.click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Scroll until page content stops updating        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)        \n",
    "\n",
    "        # Extract bus details\n",
    "        bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "        bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "        departing_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "        reaching_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "        total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "        star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price = driver.find_elements(By.XPATH, '//div[@class=\"fare d-block\"]//span')\n",
    "        seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")        \n",
    "        \n",
    "        # Collect bus details\n",
    "        for i in range(len(bus_name)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": routes,\n",
    "                \"Route_Link\": link,\n",
    "                \"Bus_Name\": bus_name[i].text if i < len(bus_name) else 'N/A',\n",
    "                \"Bus_Type\": bus_type[i].text if i < len(bus_type) else 'N/A',\n",
    "                \"Departing_Time\": departing_time[i].text if i < len(departing_time) else 'N/A',\n",
    "                \"Duration\": total_duration[i].text if i < len(total_duration) else 'N/A',\n",
    "                \"Reaching_Time\": reaching_time[i].text if i < len(reaching_time) else 'N/A',\n",
    "                \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                \"Price\": price[i].text if i < len(price) else 'N/A',\n",
    "                \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        print(f\"Successfully completed data extraction for route: {routes}\")\n",
    "\n",
    "    # Save detailed bus data to CSV\n",
    "    df_buses = pd.DataFrame(bus_details)\n",
    "    df_buses.to_csv(\"CTU_bus_details.csv\", index=False)\n",
    "    print(\"Bus details saved to bus_details.csv\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762eb01b-e01b-4023-8acc-90f89ae168cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
